---
http_interactions:
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-4.1","messages":[{"role":"system","content":"Your input
        schema fields are:\n```baml\nclass HistoryEntry {\n  step int\n  thought string?\n  action
        string?\n  tool_input map<string, json>?\n  observation json\n}\n\nclass AvailableTool
        {\n  name string\n  description string\n  schema string\n}\n\nclass SchemaInput
        {\n  input_context string\n  history HistoryEntry[]\n  available_tools AvailableTool[]\n}\n```\nYour
        output schema fields are:\n```baml\nenum ActionEnum {\n  \"load_data\"\n  \"finish\"\n}\n\nclass
        SchemaOutput {\n  thought string\n  action ActionEnum\n  tool_input map<string,
        json>?\n  final_answer string?\n}\n```\n\nAll interactions will be structured
        in the following way, with the appropriate values filled in.\n## Input values\n```json\n{input_values}\n```\n##
        Output values\nRespond exclusively with the output schema fields in the json
        block below.\n```json\n{output_values}\n```\n\nIn adhering to this structure,
        your objective is: Generate a thought about what to do next to process the
        given inputs."},{"role":"user","content":"## Input Values\n```json\n{\n  \"input_context\":
        \"{\\\"_type\\\":\\\"AnonymousStruct\\\",\\\"query\\\":\\\"What data do we
        have?\\\",\\\"structured_state\\\":\\\"No prior context\\\"}\",\n  \"history\":
        [],\n  \"available_tools\": [\n    {\n      \"name\": \"load_data\",\n      \"description\":
        \"Loads some dummy data\",\n      \"schema\": \"{\\\"name\\\":\\\"load_data\\\",\\\"description\\\":\\\"Loads
        some dummy data\\\",\\\"parameters\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"data_type\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"Parameter
        data_type\\\"}},\\\"required\\\":[\\\"data_type\\\"]}}\"\n    }\n  ]\n}\n```\n\nRespond
        with the corresponding output schema fields wrapped in a ```json ``` block,\nstarting
        with the heading `## Output values`."}],"temperature":0.0}'
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - application/json
      User-Agent:
      - OpenAI::Client/Ruby 0.36.0
      Host:
      - api.openai.com
      X-Stainless-Arch:
      - arm64
      X-Stainless-Lang:
      - ruby
      X-Stainless-Os:
      - MacOS
      X-Stainless-Package-Version:
      - 0.36.0
      X-Stainless-Runtime:
      - ruby
      X-Stainless-Runtime-Version:
      - 3.4.5
      Content-Type:
      - application/json
      Authorization:
      - Bearer <OPENAI_API_KEY>
      X-Stainless-Retry-Count:
      - '0'
      X-Stainless-Timeout:
      - '600.0'
      Content-Length:
      - '1877'
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Thu, 11 Dec 2025 14:34:15 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Access-Control-Expose-Headers:
      - X-Request-ID
      Openai-Organization:
      - "<OPENAI_ORGANIZATION>"
      Openai-Processing-Ms:
      - '1293'
      Openai-Project:
      - proj_n52OL5vlzVaXGnYDaGWmVX5F
      Openai-Version:
      - '2020-10-01'
      X-Envoy-Upstream-Service-Time:
      - '1348'
      X-Ratelimit-Limit-Requests:
      - '500'
      X-Ratelimit-Limit-Tokens:
      - '30000'
      X-Ratelimit-Remaining-Requests:
      - '499'
      X-Ratelimit-Remaining-Tokens:
      - '29598'
      X-Ratelimit-Reset-Requests:
      - 120ms
      X-Ratelimit-Reset-Tokens:
      - 804ms
      X-Request-Id:
      - "<REQUEST_ID>"
      X-Openai-Proxy-Wasm:
      - v0.1
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - __cf_bm=<REDACTED>
      - _cfuvid=<REDACTED>
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      X-Content-Type-Options:
      - nosniff
      Server:
      - cloudflare
      Cf-Ray:
      - 9ac5b39c5f61f3fc-MAD
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "id": "chatcmpl-Clc29qcYNJVljxvENrY0jO2Mvm3eL",
          "object": "chat.completion",
          "created": 1765463653,
          "model": "gpt-4.1-2025-04-14",
          "choices": [
            {
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "## Output values\n```json\n{\n  \"thought\": \"The user is asking about what data is available. I should load the available data to answer this question.\",\n  \"action\": \"load_data\",\n  \"tool_input\": {\n    \"data_type\": \"all\"\n  },\n  \"final_answer\": null\n}\n```",
                "refusal": null,
                "annotations": []
              },
              "logprobs": null,
              "finish_reason": "stop"
            }
          ],
          "usage": {
            "prompt_tokens": 373,
            "completion_tokens": 67,
            "total_tokens": 440,
            "prompt_tokens_details": {
              "cached_tokens": 0,
              "audio_tokens": 0
            },
            "completion_tokens_details": {
              "reasoning_tokens": 0,
              "audio_tokens": 0,
              "accepted_prediction_tokens": 0,
              "rejected_prediction_tokens": 0
            }
          },
          "service_tier": "default",
          "system_fingerprint": "fp_09249d7c7b"
        }
  recorded_at: Thu, 11 Dec 2025 14:34:15 GMT
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-4.1","messages":[{"role":"system","content":"Your input
        schema fields are:\n```baml\nclass HistoryEntry {\n  step int\n  thought string?\n  action
        string?\n  tool_input map<string, json>?\n  observation json\n}\n\nclass SchemaInput
        {\n  input_context string\n  history HistoryEntry[]\n  observation json\n}\n```\nYour
        output schema fields are:\n```baml\nenum NextStep {\n  \"continue\"\n  \"finish\"\n}\n\nclass
        SchemaOutput {\n  interpretation string\n  next_step NextStep\n}\n```\n\nAll
        interactions will be structured in the following way, with the appropriate
        values filled in.\n## Input values\n```json\n{input_values}\n```\n## Output
        values\nRespond exclusively with the output schema fields in the json block
        below.\n```json\n{output_values}\n```\n\nIn adhering to this structure, your
        objective is: Process the observation from a tool and decide what to do next."},{"role":"user","content":"##
        Input Values\n```json\n{\n  \"input_context\": \"{\\\"_type\\\":\\\"AnonymousStruct\\\",\\\"query\\\":\\\"What
        data do we have?\\\",\\\"structured_state\\\":\\\"No prior context\\\"}\",\n  \"history\":
        [\n    {\n      \"step\": 1,\n      \"thought\": \"The user is asking about
        what data is available. I should load the available data to answer this question.\",\n      \"action\":
        \"load_data\",\n      \"tool_input\": {\n        \"data_type\": \"all\"\n      },\n      \"observation\":
        \"Loaded data for: all\"\n    }\n  ],\n  \"observation\": \"Loaded data for:
        all\"\n}\n```\n\nRespond with the corresponding output schema fields wrapped
        in a ```json ``` block,\nstarting with the heading `## Output values`."}],"temperature":0.0}'
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - application/json
      User-Agent:
      - OpenAI::Client/Ruby 0.36.0
      Host:
      - api.openai.com
      X-Stainless-Arch:
      - arm64
      X-Stainless-Lang:
      - ruby
      X-Stainless-Os:
      - MacOS
      X-Stainless-Package-Version:
      - 0.36.0
      X-Stainless-Runtime:
      - ruby
      X-Stainless-Runtime-Version:
      - 3.4.5
      Content-Type:
      - application/json
      Authorization:
      - Bearer <OPENAI_API_KEY>
      X-Stainless-Retry-Count:
      - '0'
      X-Stainless-Timeout:
      - '600.0'
      Content-Length:
      - '1650'
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Thu, 11 Dec 2025 14:34:16 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Access-Control-Expose-Headers:
      - X-Request-ID
      Openai-Organization:
      - "<OPENAI_ORGANIZATION>"
      Openai-Processing-Ms:
      - '757'
      Openai-Project:
      - proj_n52OL5vlzVaXGnYDaGWmVX5F
      Openai-Version:
      - '2020-10-01'
      X-Envoy-Upstream-Service-Time:
      - '773'
      X-Ratelimit-Limit-Requests:
      - '500'
      X-Ratelimit-Limit-Tokens:
      - '30000'
      X-Ratelimit-Remaining-Requests:
      - '499'
      X-Ratelimit-Remaining-Tokens:
      - '29641'
      X-Ratelimit-Reset-Requests:
      - 120ms
      X-Ratelimit-Reset-Tokens:
      - 718ms
      X-Request-Id:
      - "<REQUEST_ID>"
      X-Openai-Proxy-Wasm:
      - v0.1
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - __cf_bm=<REDACTED>
      - _cfuvid=<REDACTED>
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      X-Content-Type-Options:
      - nosniff
      Server:
      - cloudflare
      Cf-Ray:
      - 9ac5b3a5c888f3fc-MAD
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "id": "chatcmpl-Clc2B1qIuZLlsbJ7lJmI3Al5hFQYo",
          "object": "chat.completion",
          "created": 1765463655,
          "model": "gpt-4.1-2025-04-14",
          "choices": [
            {
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "## Output values\n```json\n{\n  \"interpretation\": \"The data has been successfully loaded. I can now summarize or list the available data to answer the user's question.\",\n  \"next_step\": \"finish\"\n}\n```",
                "refusal": null,
                "annotations": []
              },
              "logprobs": null,
              "finish_reason": "stop"
            }
          ],
          "usage": {
            "prompt_tokens": 347,
            "completion_tokens": 46,
            "total_tokens": 393,
            "prompt_tokens_details": {
              "cached_tokens": 0,
              "audio_tokens": 0
            },
            "completion_tokens_details": {
              "reasoning_tokens": 0,
              "audio_tokens": 0,
              "accepted_prediction_tokens": 0,
              "rejected_prediction_tokens": 0
            }
          },
          "service_tier": "default",
          "system_fingerprint": "fp_503841a4dc"
        }
  recorded_at: Thu, 11 Dec 2025 14:34:16 GMT
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-4.1","messages":[{"role":"system","content":"Your input
        schema fields are:\n```baml\nclass HistoryEntry {\n  step int\n  thought string?\n  action
        string?\n  tool_input map<string, json>?\n  observation json\n}\n\nclass AvailableTool
        {\n  name string\n  description string\n  schema string\n}\n\nclass SchemaInput
        {\n  input_context string\n  history HistoryEntry[]\n  available_tools AvailableTool[]\n}\n```\nYour
        output schema fields are:\n```baml\nenum ActionEnum {\n  \"load_data\"\n  \"finish\"\n}\n\nclass
        SchemaOutput {\n  thought string\n  action ActionEnum\n  tool_input map<string,
        json>?\n  final_answer string?\n}\n```\n\nAll interactions will be structured
        in the following way, with the appropriate values filled in.\n## Input values\n```json\n{input_values}\n```\n##
        Output values\nRespond exclusively with the output schema fields in the json
        block below.\n```json\n{output_values}\n```\n\nIn adhering to this structure,
        your objective is: Generate a thought about what to do next to process the
        given inputs."},{"role":"user","content":"## Input Values\n```json\n{\n  \"input_context\":
        \"{\\\"_type\\\":\\\"AnonymousStruct\\\",\\\"query\\\":\\\"What data do we
        have?\\\",\\\"structured_state\\\":\\\"No prior context\\\"}\",\n  \"history\":
        [\n    {\n      \"step\": 1,\n      \"thought\": \"The user is asking about
        what data is available. I should load the available data to answer this question.\",\n      \"action\":
        \"load_data\",\n      \"tool_input\": {\n        \"data_type\": \"all\"\n      },\n      \"observation\":
        \"Loaded data for: all\"\n    }\n  ],\n  \"available_tools\": [\n    {\n      \"name\":
        \"load_data\",\n      \"description\": \"Loads some dummy data\",\n      \"schema\":
        \"{\\\"name\\\":\\\"load_data\\\",\\\"description\\\":\\\"Loads some dummy
        data\\\",\\\"parameters\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"data_type\\\":{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"Parameter
        data_type\\\"}},\\\"required\\\":[\\\"data_type\\\"]}}\"\n    }\n  ]\n}\n```\n\nRespond
        with the corresponding output schema fields wrapped in a ```json ``` block,\nstarting
        with the heading `## Output values`."}],"temperature":0.0}'
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - application/json
      User-Agent:
      - OpenAI::Client/Ruby 0.36.0
      Host:
      - api.openai.com
      X-Stainless-Arch:
      - arm64
      X-Stainless-Lang:
      - ruby
      X-Stainless-Os:
      - MacOS
      X-Stainless-Package-Version:
      - 0.36.0
      X-Stainless-Runtime:
      - ruby
      X-Stainless-Runtime-Version:
      - 3.4.5
      Content-Type:
      - application/json
      Authorization:
      - Bearer <OPENAI_API_KEY>
      X-Stainless-Retry-Count:
      - '0'
      X-Stainless-Timeout:
      - '600.0'
      Content-Length:
      - '2197'
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Thu, 11 Dec 2025 14:34:21 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Access-Control-Expose-Headers:
      - X-Request-ID
      Openai-Organization:
      - "<OPENAI_ORGANIZATION>"
      Openai-Processing-Ms:
      - '2855'
      Openai-Project:
      - proj_n52OL5vlzVaXGnYDaGWmVX5F
      Openai-Version:
      - '2020-10-01'
      X-Envoy-Upstream-Service-Time:
      - '4626'
      X-Ratelimit-Limit-Requests:
      - '500'
      X-Ratelimit-Limit-Tokens:
      - '30000'
      X-Ratelimit-Remaining-Requests:
      - '499'
      X-Ratelimit-Remaining-Tokens:
      - '29525'
      X-Ratelimit-Reset-Requests:
      - 120ms
      X-Ratelimit-Reset-Tokens:
      - 950ms
      X-Request-Id:
      - "<REQUEST_ID>"
      X-Openai-Proxy-Wasm:
      - v0.1
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - __cf_bm=<REDACTED>
      - _cfuvid=<REDACTED>
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      X-Content-Type-Options:
      - nosniff
      Server:
      - cloudflare
      Cf-Ray:
      - 9ac5b3abea64f3fc-MAD
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "id": "chatcmpl-Clc2E8VZfndoGVDqaWtpK6FIojTQH",
          "object": "chat.completion",
          "created": 1765463658,
          "model": "gpt-4.1-2025-04-14",
          "choices": [
            {
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "## Output values\n```json\n{\n  \"thought\": \"I have already loaded all available data in the previous step, so I can now provide the user with an answer about what data is available.\",\n  \"action\": \"finish\",\n  \"final_answer\": \"All available data has been loaded. Please specify what information you would like to know about the data, or if you need a summary of its contents.\"\n}\n```",
                "refusal": null,
                "annotations": []
              },
              "logprobs": null,
              "finish_reason": "stop"
            }
          ],
          "usage": {
            "prompt_tokens": 448,
            "completion_tokens": 86,
            "total_tokens": 534,
            "prompt_tokens_details": {
              "cached_tokens": 0,
              "audio_tokens": 0
            },
            "completion_tokens_details": {
              "reasoning_tokens": 0,
              "audio_tokens": 0,
              "accepted_prediction_tokens": 0,
              "rejected_prediction_tokens": 0
            }
          },
          "service_tier": "default",
          "system_fingerprint": "fp_09249d7c7b"
        }
  recorded_at: Thu, 11 Dec 2025 14:34:21 GMT
recorded_with: VCR 6.3.1
