---
http_interactions:
- request:
    method: post
    uri: https://collector.newrelic.com/agent_listener/invoke_raw_method?license_key=<NEW_RELIC_LICENSE_KEY>&marshal_format=json&method=log_event_data&protocol_version=17&run_id=BT-_PHzm4ZnbADvrtB84K3ppOY1IAAEBAAAnIQEAAH3KAgQfPOcaAwAGOS4yMS4wAAtzaW1iYS5sb2NhbAAHRFNQeS5yYg
    body:
      encoding: UTF-8
      string: '[{"common":{"attributes":{"entity.name":"DSPy.rb","hostname":"simba.local","entity.guid":"MzkyNjk2NHxBUE18QVBQTElDQVRJT058NTI0MDg1MDE4"}},"logs":[{"level":"INFO","timestamp":1765379329919.728,"message":"trace_id=\"04dc9efd-fe21-4786-b129-8a8ece78bcc2\"
        input_tokens=260 output_tokens=135 total_tokens=395 gen_ai.system=\"openai\"
        gen_ai.request.model=\"gpt-4o-mini\" dspy.signature=\"DSPy::RubyCodeGeneration\"
        module_path=[{id: \"f65d0ac4-aad8-41ef-850c-3d1cd51b4098\", class: \"DSPy::CodeAct\",
        label: nil}, {id: \"04868833-1e07-471e-9c48-d724e59ba836\", class: \"DSPy::Predict\",
        label: nil}] module_root={id: \"f65d0ac4-aad8-41ef-850c-3d1cd51b4098\", class:
        \"DSPy::CodeAct\", label: nil} module_leaf={id: \"04868833-1e07-471e-9c48-d724e59ba836\",
        class: \"DSPy::Predict\", label: nil} module_scope={ancestry_token: \"f65d0ac4-aad8-41ef-850c-3d1cd51b4098>04868833-1e07-471e-9c48-d724e59ba836\",
        depth: 2} event=\"lm.tokens\"\n"},{"level":"INFO","timestamp":1765379331722.913,"message":"trace_id=\"04dc9efd-fe21-4786-b129-8a8ece78bcc2\"
        input_tokens=404 output_tokens=52 total_tokens=456 gen_ai.system=\"openai\"
        gen_ai.request.model=\"gpt-4o-mini\" dspy.signature=\"DSPy::RubyCodeObservation\"
        module_path=[{id: \"f65d0ac4-aad8-41ef-850c-3d1cd51b4098\", class: \"DSPy::CodeAct\",
        label: nil}, {id: \"dd1aa228-b19d-4089-9966-3e60f663e621\", class: \"DSPy::Predict\",
        label: nil}] module_root={id: \"f65d0ac4-aad8-41ef-850c-3d1cd51b4098\", class:
        \"DSPy::CodeAct\", label: nil} module_leaf={id: \"dd1aa228-b19d-4089-9966-3e60f663e621\",
        class: \"DSPy::Predict\", label: nil} module_scope={ancestry_token: \"f65d0ac4-aad8-41ef-850c-3d1cd51b4098>dd1aa228-b19d-4089-9966-3e60f663e621\",
        depth: 2} event=\"lm.tokens\"\n"}]}]'
    headers:
      Content-Encoding:
      - identity
      Host:
      - collector.newrelic.com
      Nr-Utilizationmetadata:
      - AQICFgALc2ltYmEubG9jYWwXAAtzaW1iYS5sb2NhbA
      Nr-Utilizationextra:
      - AQARAAUAAAAIAABgAA
      Nr-Session:
      - BT-_PHzm4ZnbADvrtB84K3ppOY1IAAEBAAAnIQEAAH3KAgQfPOcaAwAGOS4yMS4wAAtzaW1iYS5sb2NhbAAHRFNQeS5yYg
      Nr-Agenttags:
      - AX2uHIkGAAlhY2NvdW50SWQABzM5MjY5NjQAEHRydXN0ZWRBY2NvdW50SWQABzM5MjY5NjQAB2FjY291bnQAD0FjY291bnQgMzkyNjk2NA
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - "*/*"
      User-Agent:
      - NewRelic-RubyAgent/9.21.0 (ruby 3.4.5 arm64-darwin23) zlib/1.2.12
      Content-Type:
      - application/octet-stream
  response:
    status:
      code: 202
      message: ''
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '0'
      Content-Type:
      - application/json; charset=UTF-8
      X-Envoy-Upstream-Service-Time:
      - '0'
      Date:
      - Wed, 10 Dec 2025 15:08:53 GMT
      Server:
      - envoy
      Nr-Rate-Limited:
      - allowed
      X-Served-By:
      - cache-mad2200102-MAD
    body:
      encoding: UTF-8
      string: ''
  recorded_at: Wed, 10 Dec 2025 15:08:53 GMT
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-4o-mini","messages":[{"role":"system","content":"Your
        input schema fields (TOON order) are:\n- task (String) — JSON representation
        of all input fields for the task\n- context (String) — Available variables
        and previous results from code execution history\n- history (Array<CodeActHistoryEntry>)
        — Previous thoughts and code executions with their results. Use this to understand
        what has been tried and what variables are available.\n    • Tabular columns:
        step, thought, ruby_code, execution_result, error_message\n\nYour output schema
        fields (TOON order) are:\n- thought (String) — Reasoning about the approach
        to solve the task with Ruby code\n- ruby_code (String) — Ruby code to execute.
        This should be valid Ruby code that can be evaluated safely. Avoid system
        calls, file operations, or other potentially dangerous operations.\n- explanation
        (String) — Brief explanation of what the code does and why this approach was
        chosen\n\nAll interactions will be structured in the following way, with the
        appropriate values filled in.\n## TOON data format instructions\nAll input
        and output payloads must use Token-Oriented Object Notation (TOON). Do not
        return JSON, YAML, or prose.\n\n## Input values\nCopy the TOON block below
        and replace the placeholder values with the correct inputs.\n```toon\n{input_values}\n```\n\n###
        Example TOON input\n```toon\ntask: example_task\ncontext: example_context\nhistory[1]{step,thought,ruby_code,execution_result,error_message}:\n  1,example_thought,example_ruby_code,example_execution_result,example_error_message\n```\n\n##
        Output values\nRespond exclusively with a ```toon``` block that lists the
        output fields in the exact order shown in the schema.\n```toon\n{output_values}\n```\n\n###
        Example TOON output\n```toon\nthought: example_thought\nruby_code: example_ruby_code\nexplanation:
        example_explanation\n```\n\nIn adhering to this structure, your objective
        is: Generate Ruby code to solve the given task."},{"role":"user","content":"##
        Input Values\nUse the TOON block below as-is; do not convert it to JSON.\n```toon\ntask:
        \"{\\\"_type\\\":\\\"AnonymousStruct\\\",\\\"task\\\":\\\"Calculate the product
        of 6 and 9\\\"}\"\ncontext: No previous context available.\nhistory[0]:\n```\n\nRespond
        with the corresponding output schema fields encoded as TOON inside a ```toon```
        block starting with the heading `## Output values`. Do not include any JSON."}],"temperature":1.0}'
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - application/json
      User-Agent:
      - OpenAI::Client/Ruby 0.36.0
      Host:
      - api.openai.com
      X-Stainless-Arch:
      - arm64
      X-Stainless-Lang:
      - ruby
      X-Stainless-Os:
      - MacOS
      X-Stainless-Package-Version:
      - 0.36.0
      X-Stainless-Runtime:
      - ruby
      X-Stainless-Runtime-Version:
      - 3.4.5
      Content-Type:
      - application/json
      Authorization:
      - Bearer <OPENAI_API_KEY>
      X-Stainless-Retry-Count:
      - '0'
      X-Stainless-Timeout:
      - '600.0'
      Content-Length:
      - '2443'
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Wed, 10 Dec 2025 15:08:53 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Access-Control-Expose-Headers:
      - X-Request-ID
      Openai-Organization:
      - "<OPENAI_ORGANIZATION>"
      Openai-Processing-Ms:
      - '1987'
      Openai-Project:
      - proj_n52OL5vlzVaXGnYDaGWmVX5F
      Openai-Version:
      - '2020-10-01'
      X-Envoy-Upstream-Service-Time:
      - '2000'
      X-Ratelimit-Limit-Requests:
      - '10000'
      X-Ratelimit-Limit-Tokens:
      - '200000'
      X-Ratelimit-Remaining-Requests:
      - '9996'
      X-Ratelimit-Remaining-Tokens:
      - '199431'
      X-Ratelimit-Reset-Requests:
      - 30.205s
      X-Ratelimit-Reset-Tokens:
      - 170ms
      X-Request-Id:
      - "<REQUEST_ID>"
      X-Openai-Proxy-Wasm:
      - v0.1
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - __cf_bm=<REDACTED>
      - _cfuvid=<REDACTED>
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      X-Content-Type-Options:
      - nosniff
      Server:
      - cloudflare
      Cf-Ray:
      - 9abda8f7bdd8ecaa-MAD
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "id": "chatcmpl-ClG67BhQzlCOuEXiKp3NX3w84S39e",
          "object": "chat.completion",
          "created": 1765379331,
          "model": "gpt-4o-mini-2024-07-18",
          "choices": [
            {
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "```toon\nthought: To calculate the product of 6 and 9, I will simply multiply these two numbers using Ruby's multiplication operator. This is straightforward as it involves a basic arithmetic operation.\nruby_code: 6 * 9\nexplanation: The code multiplies the integers 6 and 9 to obtain the product. This approach was chosen because it directly solves the task of finding the product.\n```",
                "refusal": null,
                "annotations": []
              },
              "logprobs": null,
              "finish_reason": "stop"
            }
          ],
          "usage": {
            "prompt_tokens": 510,
            "completion_tokens": 84,
            "total_tokens": 594,
            "prompt_tokens_details": {
              "cached_tokens": 0,
              "audio_tokens": 0
            },
            "completion_tokens_details": {
              "reasoning_tokens": 0,
              "audio_tokens": 0,
              "accepted_prediction_tokens": 0,
              "rejected_prediction_tokens": 0
            }
          },
          "service_tier": "default",
          "system_fingerprint": "fp_aa07c96156"
        }
  recorded_at: Wed, 10 Dec 2025 15:08:54 GMT
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-4o-mini","messages":[{"role":"system","content":"Your
        input schema fields (TOON order) are:\n- task (String) — JSON representation
        of all input fields for the task\n- history (Array<CodeActHistoryEntry>) —
        Previous thoughts, code executions, and their results\n    • Tabular columns:
        step, thought, ruby_code, execution_result, error_message\n- execution_result
        (String, optional) — The result from executing the Ruby code\n- error_message
        (String) — Error message if the code execution failed (empty string if no
        error)\n\nYour output schema fields (TOON order) are:\n- observation (String)
        — Analysis of the execution result and what it means for solving the task\n-
        next_step (Enum<continue, finish>) — What to do next: ''#<DSPy::CodeActNextStep::Continue>''
        to continue with more code or ''#<DSPy::CodeActNextStep::Finish>'' if the
        task is complete\n- final_answer (String, optional) — If next_step is ''finish'',
        provide the final answer to the task based on the execution results\n\nAll
        interactions will be structured in the following way, with the appropriate
        values filled in.\n## TOON data format instructions\nAll input and output
        payloads must use Token-Oriented Object Notation (TOON). Do not return JSON,
        YAML, or prose.\n\n## Input values\nCopy the TOON block below and replace
        the placeholder values with the correct inputs.\n```toon\n{input_values}\n```\n\n###
        Example TOON input\n```toon\ntask: example_task\nhistory[1]{step,thought,ruby_code,execution_result,error_message}:\n  1,example_thought,example_ruby_code,example_execution_result,example_error_message\nexecution_result:
        example_execution_result\nerror_message: example_error_message\n```\n\n##
        Output values\nRespond exclusively with a ```toon``` block that lists the
        output fields in the exact order shown in the schema.\n```toon\n{output_values}\n```\n\n###
        Example TOON output\n```toon\nobservation: example_observation\nnext_step:
        continue\nfinal_answer: example_final_answer\n```\n\nIn adhering to this structure,
        your objective is: Process the result of Ruby code execution and decide what
        to do next."},{"role":"user","content":"## Input Values\nUse the TOON block
        below as-is; do not convert it to JSON.\n```toon\ntask: \"{\\\"_type\\\":\\\"AnonymousStruct\\\",\\\"task\\\":\\\"Calculate
        the product of 6 and 9\\\"}\"\nhistory[1]{step,thought,ruby_code,execution_result,error_message}:\n  1,\"To
        calculate the product of 6 and 9, I will simply multiply these two numbers
        using Ruby''s multiplication operator. This is straightforward as it involves
        a basic arithmetic operation.\",6 * 9,\"54\",\"\"\nexecution_result: \"54\"\nerror_message:
        \"\"\n```\n\nRespond with the corresponding output schema fields encoded as
        TOON inside a ```toon``` block starting with the heading `## Output values`.
        Do not include any JSON."}],"temperature":1.0}'
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - application/json
      User-Agent:
      - OpenAI::Client/Ruby 0.36.0
      Host:
      - api.openai.com
      X-Stainless-Arch:
      - arm64
      X-Stainless-Lang:
      - ruby
      X-Stainless-Os:
      - MacOS
      X-Stainless-Package-Version:
      - 0.36.0
      X-Stainless-Runtime:
      - ruby
      X-Stainless-Runtime-Version:
      - 3.4.5
      Content-Type:
      - application/json
      Authorization:
      - Bearer <OPENAI_API_KEY>
      X-Stainless-Retry-Count:
      - '0'
      X-Stainless-Timeout:
      - '600.0'
      Content-Length:
      - '2850'
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Wed, 10 Dec 2025 15:08:55 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Access-Control-Expose-Headers:
      - X-Request-ID
      Openai-Organization:
      - "<OPENAI_ORGANIZATION>"
      Openai-Processing-Ms:
      - '1734'
      Openai-Project:
      - proj_n52OL5vlzVaXGnYDaGWmVX5F
      Openai-Version:
      - '2020-10-01'
      X-Envoy-Upstream-Service-Time:
      - '1746'
      X-Ratelimit-Limit-Requests:
      - '10000'
      X-Ratelimit-Limit-Tokens:
      - '200000'
      X-Ratelimit-Remaining-Requests:
      - '9995'
      X-Ratelimit-Remaining-Tokens:
      - '199333'
      X-Ratelimit-Reset-Requests:
      - 36.611s
      X-Ratelimit-Reset-Tokens:
      - 200ms
      X-Request-Id:
      - "<REQUEST_ID>"
      X-Openai-Proxy-Wasm:
      - v0.1
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - __cf_bm=<REDACTED>
      - _cfuvid=<REDACTED>
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      X-Content-Type-Options:
      - nosniff
      Server:
      - cloudflare
      Cf-Ray:
      - 9abda905c933ecaa-MAD
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "id": "chatcmpl-ClG6AAh8dhEY9AcXTooYMAFneSgia",
          "object": "chat.completion",
          "created": 1765379334,
          "model": "gpt-4o-mini-2024-07-18",
          "choices": [
            {
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "```toon\nobservation: \"The execution result is 54, which is the correct product of 6 and 9. The calculation was performed successfully without any errors.\"\nnext_step: finish\nfinal_answer: \"The product of 6 and 9 is 54.\"\n```",
                "refusal": null,
                "annotations": []
              },
              "logprobs": null,
              "finish_reason": "stop"
            }
          ],
          "usage": {
            "prompt_tokens": 619,
            "completion_tokens": 57,
            "total_tokens": 676,
            "prompt_tokens_details": {
              "cached_tokens": 0,
              "audio_tokens": 0
            },
            "completion_tokens_details": {
              "reasoning_tokens": 0,
              "audio_tokens": 0,
              "accepted_prediction_tokens": 0,
              "rejected_prediction_tokens": 0
            }
          },
          "service_tier": "default",
          "system_fingerprint": "fp_aa07c96156"
        }
  recorded_at: Wed, 10 Dec 2025 15:08:55 GMT
recorded_with: VCR 6.3.1
